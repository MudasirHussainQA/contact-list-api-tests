name: ğŸŒ™ Nightly Full Test Suite

on:
  schedule:
    # Run every night at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      test_type:
        description: 'Test type to run'
        required: true
        default: 'all'
        type: choice
        options:
          - all
          - api
          - ui
          - cross-browser

env:
  NODE_VERSION: '20.x'

jobs:
  # Job 1: API Tests (Fast feedback)
  api-tests:
    name: ğŸ”§ API Tests
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
      - name: ğŸ“¥ Checkout repository
        uses: actions/checkout@v4

      - name: ğŸŸ¢ Setup Node.js ${{ env.NODE_VERSION }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: ğŸ“¦ Install dependencies
        run: npm ci

      - name: ğŸ§ª Run API tests
        run: npm run test:api
        env:
          CI: true

      - name: ğŸ“Š Upload API test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: api-test-results
          path: test-results/
          retention-days: 7

  # Job 2: Cross-browser testing (nightly only)
  cross-browser-tests:
    name: ğŸŒ Cross-Browser Tests (${{ matrix.browser }})
    runs-on: ubuntu-latest
    timeout-minutes: 45
    strategy:
      fail-fast: false
      matrix:
        browser: [chromium, firefox, webkit]
    
    steps:
      - name: ğŸ“¥ Checkout repository
        uses: actions/checkout@v4

      - name: ğŸŸ¢ Setup Node.js ${{ env.NODE_VERSION }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: ğŸ“¦ Install dependencies
        run: npm ci

      - name: ğŸ­ Install Playwright browsers
        run: npx playwright install ${{ matrix.browser }} --with-deps

      - name: ğŸ§ª Run UI tests on ${{ matrix.browser }}
        run: npx playwright test --project=ui-tests-${{ matrix.browser }}
        env:
          CI: true

      - name: ğŸ“Š Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: cross-browser-test-results-${{ matrix.browser }}
          path: test-results/
          retention-days: 7

  # Job 3: Test Report Generation
  test-report:
    name: ğŸ“ˆ Generate Test Report
    runs-on: ubuntu-latest
    needs: [api-tests, cross-browser-tests]
    if: always()
    
    steps:
      - name: ğŸ“¥ Checkout repository
        uses: actions/checkout@v4

      - name: ğŸ“‹ List available artifacts
        run: |
          echo "ğŸ“Š Job status summary:"
          echo "API Tests: ${{ needs.api-tests.result }}"
          echo "Cross-browser Tests: ${{ needs.cross-browser-tests.result }}"

      - name: ğŸ“¥ Download all test results
        uses: actions/download-artifact@v4
        with:
          path: all-test-results
        continue-on-error: true

      - name: ğŸŸ¢ Setup Node.js ${{ env.NODE_VERSION }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: ğŸ“¦ Install dependencies
        run: npm ci

      - name: ğŸ“Š Merge test reports
        run: |
          echo "ğŸ“ Checking current directory:"
          pwd
          ls -la
          
          echo "ğŸ“ Checking if all-test-results exists:"
          if [ -d "./all-test-results" ]; then
            echo "âœ… all-test-results directory found"
            ls -la ./all-test-results/
            find ./all-test-results -type f | head -20
            
            # Check if we have any test result files
            if find ./all-test-results -name "*.jsonl" -o -name "*.json" | grep -q .; then
              echo "âœ… Test result files found, merging reports..."
              npx playwright merge-reports --reporter html ./all-test-results/
            else
              echo "âš ï¸ No test result files found, creating basic report..."
              mkdir -p playwright-report
              echo "<h1>ğŸŒ™ Nightly Test Results - No data to merge</h1>" > playwright-report/index.html
            fi
          else
            echo "âŒ all-test-results directory not found"
            echo "ğŸ“ Available directories:"
            ls -la
            
            # Create a basic report if no artifacts
            mkdir -p playwright-report
            echo "<h1>ğŸŒ™ Nightly Test Results - No artifacts downloaded</h1>" > playwright-report/index.html
          fi

      - name: ğŸ“¤ Upload merged report
        uses: actions/upload-artifact@v4
        with:
          name: nightly-test-report
          path: playwright-report/
          retention-days: 30

      - name: ğŸŒ Deploy report to GitHub Pages
        id: deploy-pages
        uses: peaceiris/actions-gh-pages@v3
        if: github.ref == 'refs/heads/main'
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./playwright-report
          destination_dir: nightly-reports/${{ github.run_number }}
        continue-on-error: true

      - name: ğŸ“‹ Pages deployment status
        if: github.ref == 'refs/heads/main'
        run: |
          if [ "${{ steps.deploy-pages.outcome }}" == "success" ]; then
            echo "âœ… GitHub Pages deployment successful!"
            echo "ğŸ“Š Nightly report available at: https://${{ github.repository_owner }}.github.io/${{ github.event.repository.name }}/nightly-reports/${{ github.run_number }}/"
          else
            echo "âš ï¸ GitHub Pages deployment failed or skipped"
            echo "ğŸ’¡ To enable GitHub Pages:"
            echo "   1. Go to repository Settings â†’ Pages"
            echo "   2. Source: Deploy from a branch"
            echo "   3. Branch: gh-pages"
            echo "ğŸ“Š Report still available as artifact: nightly-test-report"
          fi

  # Job 4: Notifications & Metrics
  notify:
    name: ğŸ“¢ Notify Results
    runs-on: ubuntu-latest
    needs: [api-tests, cross-browser-tests, test-report]
    if: always()
    
    steps:
      - name: ğŸ“¥ Checkout repository
        uses: actions/checkout@v4

      - name: ğŸ“¥ Download test report
        uses: actions/download-artifact@v4
        with:
          name: nightly-test-report
          path: ./report-data
        continue-on-error: true

      - name: ğŸŸ¢ Setup Node.js ${{ env.NODE_VERSION }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: ğŸ“Š Extract test metrics from HTML report
        id: extract-metrics
        run: |
          # Create a Node.js script to parse HTML report
          cat > extract-metrics.js << 'EOF'
          const fs = require('fs');
          const path = require('path');
          
          function extractMetrics() {
            try {
              const reportPath = './report-data/index.html';
              if (!fs.existsSync(reportPath)) {
                console.log('No HTML report found, using basic metrics');
                return {
                  totalTests: 'N/A',
                  passed: 'N/A',
                  failed: 'N/A',
                  skipped: 'N/A',
                  duration: 'N/A',
                  summary: 'Report not available'
                };
              }
              
              const htmlContent = fs.readFileSync(reportPath, 'utf8');
              
              // Extract metrics using regex patterns
              const totalMatch = htmlContent.match(/(\d+)\s*tests?\s*ran/i) || htmlContent.match(/Total:\s*(\d+)/i);
              const passedMatch = htmlContent.match(/(\d+)\s*passed/i);
              const failedMatch = htmlContent.match(/(\d+)\s*failed/i);
              const skippedMatch = htmlContent.match(/(\d+)\s*skipped/i);
              const durationMatch = htmlContent.match(/(\d+(?:\.\d+)?[ms]+)/i);
              
              const metrics = {
                totalTests: totalMatch ? totalMatch[1] : 'N/A',
                passed: passedMatch ? passedMatch[1] : 'N/A',
                failed: failedMatch ? failedMatch[1] : 'N/A',
                skipped: skippedMatch ? skippedMatch[1] : 'N/A',
                duration: durationMatch ? durationMatch[1] : 'N/A',
                summary: `${passedMatch ? passedMatch[1] : '0'} passed, ${failedMatch ? failedMatch[1] : '0'} failed`
              };
              
              return metrics;
            } catch (error) {
              console.error('Error extracting metrics:', error);
              return {
                totalTests: 'Error',
                passed: 'Error',
                failed: 'Error',
                skipped: 'Error',
                duration: 'Error',
                summary: 'Failed to parse report'
              };
            }
          }
          
          const metrics = extractMetrics();
          console.log('METRICS_JSON=' + JSON.stringify(metrics));
          EOF
          
          # Run the extraction script
          node extract-metrics.js > metrics-output.txt
          METRICS_JSON=$(cat metrics-output.txt | grep "METRICS_JSON=" | cut -d'=' -f2-)
          echo "metrics=$METRICS_JSON" >> $GITHUB_OUTPUT
          
          # Also extract individual values for easier access
          echo "$METRICS_JSON" | node -e "
            const metrics = JSON.parse(require('fs').readFileSync(0, 'utf8'));
            console.log('total_tests=' + metrics.totalTests);
            console.log('passed_tests=' + metrics.passed);
            console.log('failed_tests=' + metrics.failed);
            console.log('test_summary=' + metrics.summary);
            console.log('test_duration=' + metrics.duration);
          " >> $GITHUB_OUTPUT

      - name: ğŸ“Š Calculate test results
        id: test-results
        run: |
          API_RESULT="${{ needs.api-tests.result }}"
          BROWSER_RESULT="${{ needs.cross-browser-tests.result }}"
          
          # Count browser results
          CHROMIUM_SUCCESS=false
          FIREFOX_SUCCESS=false
          WEBKIT_SUCCESS=false
          
          # Note: This is a simplified check. In reality, we'd need to parse matrix results
          if [[ "$BROWSER_RESULT" == "success" ]]; then
            BROWSER_STATUS="âœ… All browsers passed"
            BROWSER_COLOR="good"
          else
            BROWSER_STATUS="âŒ Some browsers failed"
            BROWSER_COLOR="danger"
          fi
          
          if [[ "$API_RESULT" == "success" && "$BROWSER_RESULT" == "success" ]]; then
            echo "status=âœ… All nightly tests passed" >> $GITHUB_OUTPUT
            echo "color=good" >> $GITHUB_OUTPUT
          elif [[ "$API_RESULT" == "failure" || "$BROWSER_RESULT" == "failure" ]]; then
            echo "status=âŒ Nightly tests failed" >> $GITHUB_OUTPUT
            echo "color=danger" >> $GITHUB_OUTPUT
          else
            echo "status=âš ï¸ Nightly tests cancelled or skipped" >> $GITHUB_OUTPUT
            echo "color=warning" >> $GITHUB_OUTPUT
          fi
          
          echo "browser_status=$BROWSER_STATUS" >> $GITHUB_OUTPUT

      - name: ğŸ“¢ Enhanced Slack notification with test metrics
        uses: 8398a7/action-slack@v3
        if: always()
        with:
          status: custom
          custom_payload: |
            {
              "text": "ğŸŒ™ Nightly Test Results: ${{ steps.test-results.outputs.status }}",
              "attachments": [{
                "color": "${{ steps.test-results.outputs.color }}",
                "pretext": "ğŸ“Š *Test Summary*: ${{ steps.extract-metrics.outputs.test_summary }}",
                "fields": [{
                  "title": "Repository",
                  "value": "${{ github.repository }}",
                  "short": true
                }, {
                  "title": "Branch",
                  "value": "${{ github.ref_name }}",
                  "short": true
                }, {
                  "title": "Total Tests",
                  "value": "${{ steps.extract-metrics.outputs.total_tests }}",
                  "short": true
                }, {
                  "title": "Duration",
                  "value": "${{ steps.extract-metrics.outputs.test_duration }}",
                  "short": true
                }, {
                  "title": "âœ… Passed",
                  "value": "${{ steps.extract-metrics.outputs.passed_tests }}",
                  "short": true
                }, {
                  "title": "âŒ Failed",
                  "value": "${{ steps.extract-metrics.outputs.failed_tests }}",
                  "short": true
                }, {
                  "title": "API Tests",
                  "value": "${{ needs.api-tests.result }}",
                  "short": true
                }, {
                  "title": "Cross-Browser Tests", 
                  "value": "${{ needs.cross-browser-tests.result }}",
                  "short": true
                }, {
                  "title": "Commit",
                  "value": "`${{ github.sha }}`",
                  "short": true
                }, {
                  "title": "Triggered By",
                  "value": "${{ github.actor }}",
                  "short": true
                }],
                "actions": [{
                  "type": "button",
                  "text": "ğŸ“Š View Full Report",
                  "url": "https://${{ github.repository_owner }}.github.io/${{ github.event.repository.name }}/nightly-reports/${{ github.run_number }}/"
                }, {
                  "type": "button", 
                  "text": "ğŸ” View Workflow",
                  "url": "https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}"
                }]
              }]
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}

      - name: ğŸ“ Upload HTML report to Slack (on failures)
        if: always() && (needs.api-tests.result == 'failure' || needs.cross-browser-tests.result == 'failure')
        run: |
          if [ -f "./report-data/index.html" ]; then
            echo "ğŸ“ Uploading HTML report to Slack for failed tests..."
            
            # Create a condensed summary report for Slack
            cat > slack-summary.html << EOF
            <!DOCTYPE html>
            <html>
            <head>
              <title>ğŸŒ™ Nightly Test Summary - $(date)</title>
              <style>
                body { font-family: Arial, sans-serif; margin: 20px; }
                .header { background: #f44336; color: white; padding: 10px; border-radius: 5px; }
                .success { color: #4CAF50; }
                .failure { color: #f44336; }
                .summary { background: #f5f5f5; padding: 15px; border-radius: 5px; margin: 10px 0; }
                .metrics { display: flex; gap: 20px; }
                .metric { text-align: center; padding: 10px; background: white; border-radius: 5px; }
              </style>
            </head>
            <body>
              <div class="header">
                <h2>ğŸŒ™ Nightly Test Results - FAILED</h2>
                <p>Repository: ${{ github.repository }} | Branch: ${{ github.ref_name }}</p>
              </div>
              
              <div class="summary">
                <h3>ğŸ“Š Test Summary</h3>
                <div class="metrics">
                  <div class="metric">
                    <strong>${{ steps.extract-metrics.outputs.total_tests }}</strong><br>
                    Total Tests
                  </div>
                  <div class="metric">
                    <strong class="success">${{ steps.extract-metrics.outputs.passed_tests }}</strong><br>
                    Passed
                  </div>
                  <div class="metric">
                    <strong class="failure">${{ steps.extract-metrics.outputs.failed_tests }}</strong><br>
                    Failed
                  </div>
                  <div class="metric">
                    <strong>${{ steps.extract-metrics.outputs.test_duration }}</strong><br>
                    Duration
                  </div>
                </div>
              </div>
              
              <div class="summary">
                <h3>ğŸ”§ Job Results</h3>
                <p><strong>API Tests:</strong> ${{ needs.api-tests.result }}</p>
                <p><strong>Cross-Browser Tests:</strong> ${{ needs.cross-browser-tests.result }}</p>
              </div>
              
              <p><a href="https://${{ github.repository_owner }}.github.io/${{ github.event.repository.name }}/nightly-reports/${{ github.run_number }}/">ğŸ“Š View Full Interactive Report</a></p>
              <p><a href="https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}">ğŸ” View Workflow Details</a></p>
            </body>
            </html>
            EOF
            
            # Use curl to upload file to Slack (requires SLACK_BOT_TOKEN)
            if [ ! -z "${{ secrets.SLACK_BOT_TOKEN }}" ]; then
              curl -F file=@slack-summary.html \
                   -F "initial_comment=ğŸŒ™ Nightly Test Report Summary (Failures Detected)" \
                   -F channels=${{ secrets.SLACK_CHANNEL_ID || 'general' }} \
                   -H "Authorization: Bearer ${{ secrets.SLACK_BOT_TOKEN }}" \
                   https://slack.com/api/files.upload
            else
              echo "âš ï¸ SLACK_BOT_TOKEN not configured, skipping file upload"
              echo "ğŸ’¡ To enable file uploads, add SLACK_BOT_TOKEN to repository secrets"
            fi
          else
            echo "âš ï¸ No HTML report found to upload"
          fi
